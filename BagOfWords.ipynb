{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMb2IEFFEO1n0ECqypibczM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rkp74/BagOfWords/blob/main/BagOfWords.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "317QBVEqCAPg"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import sklearn.feature_extraction.text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6wissxnNFOn",
        "outputId": "851ab0bf-ede0-4f99-e3cd-56d6897208ef"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.1.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.22.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.10.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyF4oRfYLbLF",
        "outputId": "dbe2c58f-7336-443b-f8f8-25251b1cc5bb"
      },
      "execution_count": 85,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sltVmx2iFkss",
        "outputId": "79c373c4-7a01-4127-b1a4-b86331ae496b"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph = \"\"\"\" Deep learning is part of a broader family of machine learning methods based on artificial neural networks with representation learning. Learning can be supervised, semi-supervised or unsupervised.[2]\n",
        "\n",
        "Deep-learning architectures such as deep neural networks, deep belief networks, deep reinforcement learning, recurrent neural networks, convolutional neural networks and transformers have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance.[3][4][5]\n",
        "\n",
        "Artificial neural networks (ANNs) were inspired by information processing and distributed communication nodes in biological systems. ANNs have various differences from biological brains. Specifically, artificial neural networks tend to be static and symbolic, while the biological brain of most living organisms is dynamic (plastic) and analog.[6][7]\n",
        "\n",
        "The adjective \"deep\" in deep learning refers to the use of multiple layers in the network. Early work showed that a linear perceptron cannot be a universal classifier, but that a network with a nonpolynomial activation function with one hidden layer of unbounded width can. Deep learning is a modern variation that is concerned with an unbounded number of layers of bounded size, which permits practical application and optimized implementation, while retaining theoretical universality under mild conditions. In deep learning the layers are also permitted to be heterogeneous and to deviate widely from biologically informed connectionist models, for the sake of efficiency, trainability and understandability. \"\"\""
      ],
      "metadata": {
        "id": "9V63UvPjES6s"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cleaning the texts\n",
        "import re \n",
        "# re stands for regular expression\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "ceNlt0zFEc82"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ps = PorterStemmer()\n",
        "wn = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "yH_QJmHGE9Rf"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = nltk.sent_tokenize(paragraph)\n",
        "print(sentences)\n",
        "len(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEzetu6tFXG2",
        "outputId": "3ab64259-f4c1-4208-80ec-49b43148abc5"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\" Deep learning is part of a broader family of machine learning methods based on artificial neural networks with representation learning.', 'Learning can be supervised, semi-supervised or unsupervised.', '[2]\\n\\nDeep-learning architectures such as deep neural networks, deep belief networks, deep reinforcement learning, recurrent neural networks, convolutional neural networks and transformers have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance.', '[3][4][5]\\n\\nArtificial neural networks (ANNs) were inspired by information processing and distributed communication nodes in biological systems.', 'ANNs have various differences from biological brains.', 'Specifically, artificial neural networks tend to be static and symbolic, while the biological brain of most living organisms is dynamic (plastic) and analog.', '[6][7]\\n\\nThe adjective \"deep\" in deep learning refers to the use of multiple layers in the network.', 'Early work showed that a linear perceptron cannot be a universal classifier, but that a network with a nonpolynomial activation function with one hidden layer of unbounded width can.', 'Deep learning is a modern variation that is concerned with an unbounded number of layers of bounded size, which permits practical application and optimized implementation, while retaining theoretical universality under mild conditions.', 'In deep learning the layers are also permitted to be heterogeneous and to deviate widely from biologically informed connectionist models, for the sake of efficiency, trainability and understandability.']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = []"
      ],
      "metadata": {
        "id": "lj9TuY0lFzZi"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(sentences)):\n",
        "  review = re.sub('[^a-zA-Z]', ' ',sentences[i])\n",
        "  # In deep learning the layers are also permitted to be heterogeneous and to deviate widely from biologically informed connectionist models  for the sake of efficiency  trainability and understandability \n",
        "  \n",
        "  review = review.lower()\n",
        "  # in deep learning the layers are also permitted to be heterogeneous and to deviate widely from biologically informed connectionist models  for the sake of efficiency  trainability and understandability \n",
        "  \n",
        "  review = review.split()\n",
        "  # ['in', 'deep', 'learning', 'the', 'layers', 'are', 'also', 'permitted', 'to', 'be', 'heterogeneous', 'and', 'to', 'deviate', 'widely', 'from', 'biologically', 'informed', 'connectionist', 'models', 'for', 'the', 'sake', 'of', 'efficiency', 'trainability', 'and', 'understandability']\n",
        "  \n",
        "  #review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
        "  # ['deep', 'learn', 'layer', 'also', 'permit', 'heterogen', 'deviat', 'wide', 'biolog', 'inform', 'connectionist', 'model', 'sake', 'effici', 'trainabl', 'understand']\n",
        "  \n",
        "  review = [wn.lemmatize(word) for word in review if not word in set(stopwords.words('english'))]\n",
        "  # ['deep', 'learning', 'layer', 'also', 'permitted', 'heterogeneous', 'deviate', 'widely', 'biologically', 'informed', 'connectionist', 'model', 'sake', 'efficiency', 'trainability', 'understandability']\n",
        "  \n",
        "  review = ' '.join(review)\n",
        "  corpus.append(review)\n",
        "  print(review)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjqzziwMF85o",
        "outputId": "731e7162-ff73-4779-ba4d-9ecc0c816d87"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deep learning part broader family machine learning method based artificial neural network representation learning\n",
            "learning supervised semi supervised unsupervised\n",
            "deep learning architecture deep neural network deep belief network deep reinforcement learning recurrent neural network convolutional neural network transformer applied field including computer vision speech recognition natural language processing machine translation bioinformatics drug design medical image analysis climate science material inspection board game program produced result comparable case surpassing human expert performance\n",
            "artificial neural network anns inspired information processing distributed communication node biological system\n",
            "anns various difference biological brain\n",
            "specifically artificial neural network tend static symbolic biological brain living organism dynamic plastic analog\n",
            "adjective deep deep learning refers use multiple layer network\n",
            "early work showed linear perceptron cannot universal classifier network nonpolynomial activation function one hidden layer unbounded width\n",
            "deep learning modern variation concerned unbounded number layer bounded size permit practical application optimized implementation retaining theoretical universality mild condition\n",
            "deep learning layer also permitted heterogeneous deviate widely biologically informed connectionist model sake efficiency trainability understandability\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Bag of words Model (Document Matrix)\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer()\n",
        "X = cv.fit_transform(corpus).toarray()\n",
        "feature = cv.get_feature_names_out()\n",
        "print(feature)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEh9F2oJJg4U",
        "outputId": "d05e2e43-009a-4a95-e4b5-a4db3876e7ea"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['activation' 'adjective' 'also' 'analog' 'analysis' 'anns' 'application'\n",
            " 'applied' 'architecture' 'artificial' 'based' 'belief' 'bioinformatics'\n",
            " 'biological' 'biologically' 'board' 'bounded' 'brain' 'broader' 'cannot'\n",
            " 'case' 'classifier' 'climate' 'communication' 'comparable' 'computer'\n",
            " 'concerned' 'condition' 'connectionist' 'convolutional' 'deep' 'design'\n",
            " 'deviate' 'difference' 'distributed' 'drug' 'dynamic' 'early'\n",
            " 'efficiency' 'expert' 'family' 'field' 'function' 'game' 'heterogeneous'\n",
            " 'hidden' 'human' 'image' 'implementation' 'including' 'information'\n",
            " 'informed' 'inspection' 'inspired' 'language' 'layer' 'learning' 'linear'\n",
            " 'living' 'machine' 'material' 'medical' 'method' 'mild' 'model' 'modern'\n",
            " 'multiple' 'natural' 'network' 'neural' 'node' 'nonpolynomial' 'number'\n",
            " 'one' 'optimized' 'organism' 'part' 'perceptron' 'performance' 'permit'\n",
            " 'permitted' 'plastic' 'practical' 'processing' 'produced' 'program'\n",
            " 'recognition' 'recurrent' 'refers' 'reinforcement' 'representation'\n",
            " 'result' 'retaining' 'sake' 'science' 'semi' 'showed' 'size'\n",
            " 'specifically' 'speech' 'static' 'supervised' 'surpassing' 'symbolic'\n",
            " 'system' 'tend' 'theoretical' 'trainability' 'transformer' 'translation'\n",
            " 'unbounded' 'understandability' 'universal' 'universality' 'unsupervised'\n",
            " 'use' 'variation' 'various' 'vision' 'widely' 'width' 'work']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(feature)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLozGNJRRjYP",
        "outputId": "dd95ab22-fba4-452e-adb8-ebf961c67378"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "122"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Not Truncating array\n",
        "import numpy as np\n",
        "np.set_printoptions(threshold=np.inf)"
      ],
      "metadata": {
        "id": "RwyCvytAQnRW"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.shape(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuHyXhNWRfg5",
        "outputId": "2d45c817-92cc-4791-c88c-05fee215b262"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 122)"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxxCotMfQNWN",
        "outputId": "4efe9e60-6c39-4e74-8f5b-efad082c9477"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
            "  0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0\n",
            "  0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 2 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 1 1 0 0 1 1 0 0 1 0 0 0 0 1 0 1 0 1 1 0 0 0 1 4 1 0 0 0 1\n",
            "  0 0 0 1 0 1 0 1 0 0 1 1 0 1 0 0 1 0 1 0 2 0 0 1 1 1 0 0 0 0 0 1 4 3 0 0\n",
            "  0 0 0 0 0 0 1 0 0 0 0 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
            "  1 1 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
            "  0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1\n",
            "  0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 1 0 1 0 0 0 0 0 0 0 1 1]\n",
            " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
            "  1 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0\n",
            "  0 0 1 0 0 1 0 0 1 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0\n",
            "  0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
            "  0 0 0 1 0 0 0 0 0 0 0 1 0 0]]\n"
          ]
        }
      ]
    }
  ]
}